<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Selection Bias on Joshua Loftus</title>
    <link>/tags/selection-bias/</link>
    <description>Recent content in Selection Bias on Joshua Loftus</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>lastname at nyu.edu (Joshua Loftus)</managingEditor>
    <webMaster>lastname at nyu.edu (Joshua Loftus)</webMaster>
    <lastBuildDate>Fri, 05 Oct 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/selection-bias/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Data for good talk at Columbia Data Science Institute</title>
      <link>/post/data-for-good-talk-at-columbia-data-science-institute/</link>
      <pubDate>Fri, 05 Oct 2018 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/post/data-for-good-talk-at-columbia-data-science-institute/</guid>
      <description>I&amp;rsquo;m happy to be speaking at 1pm EST today at Columbia University on the topics of causal inference and selection bias in algorithmic fairness. I believe video will be available at the webinar link, and here are my slides.
The talk is based on work described in this survey with my coauthors Matt Kusner, Chris Russell, and Ricardo Silva. See here for the video for Matt&amp;rsquo;s oral presentation of our first paper in this line of work at NIPS 2017.</description>
    </item>
    
    <item>
      <title>A conditional approach to inference after model selection</title>
      <link>/post/conditional-approach-to-inference-after-model-selection/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/post/conditional-approach-to-inference-after-model-selection/</guid>
      <description>Overly honest research methods? A high profile case of a scientist retracting multiple papers due to p-hacking is recently gaining new attention due to a BuzzFeed article. Hopefully this will raise awareness and convince some that “keep hammering away at your data until you find want you were expecting” is a poor way to do science. But it’s possible to get things wrong, for the same reason, no matter how well-intentioned we may be.</description>
    </item>
    
    <item>
      <title>Model selection bias invalidates significance tests</title>
      <link>/post/model-selection-bias-invalidates-significance-tests/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/post/model-selection-bias-invalidates-significance-tests/</guid>
      <description>Significance tests and the reproducibility crisis Significance testing may be one of the most popular statistical tools in science. Researchers and journals often treat significance–having a \(p\)-value \(&amp;lt; 0.05\)–as indication that a finding is true and perhaps publishable. But the tests used to compute many of the \(p\)-values people still rely on today were developed over a century ago, when “computer” was still a job title. Now that we have digital computers and it’s standard practice to collect and analyze “big data,” the mathematical assumptions underlying many classical significance tests are being pushed beyond their limits.</description>
    </item>
    
  </channel>
</rss>