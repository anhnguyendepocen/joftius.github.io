<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Joshua Loftus</title>
    <link>/</link>
    <description>Recent content on Joshua Loftus</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>lastname at nyu.edu (Joshua Loftus)</managingEditor>
    <webMaster>lastname at nyu.edu (Joshua Loftus)</webMaster>
    <lastBuildDate>Mon, 18 Nov 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>A concise defense of statistical significance</title>
      <link>/post/a-concise-defense-of-significance/</link>
      <pubDate>Mon, 18 Nov 2019 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/post/a-concise-defense-of-significance/</guid>
      <description>A letter, signed by over 800 scientists and published in Nature called for an end to using p-values to decide whether data refutes or supports a scientific hypothesis. The letter has received widespread coverage and reignited an old debate.
Weaker arguments Most of the objections to p-values or the p &amp;lt; 0.05 threshold in these articles can be summarized into two categories:
 Objections that would apply to any method resulting in a yes/no decision Objections that would apply to any method with yes/no decisions that might be wrong  Banning p-values or &amp;ldquo;p &amp;lt; 0.</description>
    </item>
    
    <item>
      <title>Counterfactual privilege ICML talk</title>
      <link>/post/counterfactual-privilege-icml-talk/</link>
      <pubDate>Wed, 12 Jun 2019 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/post/counterfactual-privilege-icml-talk/</guid>
      <description>Talk at ICML2019 I’m talking about some new fairness work at ICML, here’s the schedule, slides, poster, and paper. Below is a brief description of one of the new concepts in this work.
 Counterfactual privilege: an asymmetric fairness constraint In previous work (paper, blog post) we described a causal framework for defining and understanding algorithmic fairness. We start with a mathematical model which can be represented as a graph with arrows designating causal relationships between variables, like this example:</description>
    </item>
    
    <item>
      <title>Data for good talk at Columbia Data Science Institute</title>
      <link>/post/data-for-good-talk-at-columbia-data-science-institute/</link>
      <pubDate>Fri, 05 Oct 2018 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/post/data-for-good-talk-at-columbia-data-science-institute/</guid>
      <description>(Note: links don’t work in this preview, click on the post to view).
I’m happy to be speaking at 1pm EST today at Columbia University on the topics of causal inference and selection bias in algorithmic fairness. I believe video will be available at the webinar link, and here are my slides.
The talk is based on work described in this survey with my coauthors Matt Kusner, Chris Russell, and Ricardo Silva.</description>
    </item>
    
    <item>
      <title>Russian twitter trolls attacked Bernie too</title>
      <link>/post/russian-twitter-trolls-attacked-bernie-too/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/post/russian-twitter-trolls-attacked-bernie-too/</guid>
      <description>(Foreign) Political influence campaigns on Twitter You may have seen stories about Twitter accounts operated by Russians attempting to influence the 2016 election in the United States. Much of the reporting that I’ve seen described a Simple Narrative: Russians tried to help trump and hurt Clinton, even supporting Bernie Sanders in order to attack Clinton. I’ve also seen plenty of Democrats on Twitter attacking Sanders over this. I have not seen any stories reporting the fact that many of these bots also attacked Sanders.</description>
    </item>
    
    <item>
      <title>A conditional approach to inference after model selection</title>
      <link>/post/conditional-approach-to-inference-after-model-selection/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/post/conditional-approach-to-inference-after-model-selection/</guid>
      <description>Overly honest research methods? A high profile case of a scientist retracting multiple papers due to p-hacking is recently gaining new attention due to a BuzzFeed article. Hopefully this will raise awareness and convince some that “keep hammering away at your data until you find want you were expecting” is a poor way to do science. But it’s possible to get things wrong, for the same reason, no matter how well-intentioned we may be.</description>
    </item>
    
    <item>
      <title>Algorithmic fairness is as hard as causation</title>
      <link>/post/algorithmic-fairness-is-as-hard-as-causation/</link>
      <pubDate>Fri, 23 Feb 2018 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/post/algorithmic-fairness-is-as-hard-as-causation/</guid>
      <description>What is algorithmic fairness? (Feel free to skip this section if you’re already familiar with the topic.)
Algorithmic fairness is an interdisciplinary research field concerned with the various ways that algorithms may perpetuate or reinforce unfair legacies of our history, and how we might modify the alorithms or systems they are used in to prevent this. For example, if the training data used in a machine learning methods contains patterns caused by things like racism, sexism, ableism, or other types of injustice, then the model may learn those patterns and use them to make predictions and decisions that are unfair.</description>
    </item>
    
    <item>
      <title>Model selection bias invalidates significance tests</title>
      <link>/post/model-selection-bias-invalidates-significance-tests/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/post/model-selection-bias-invalidates-significance-tests/</guid>
      <description>Significance tests and the reproducibility crisis Significance testing may be one of the most popular statistical tools in science. Researchers and journals often treat significance–having a \(p\)-value \(&amp;lt; 0.05\)–as indication that a finding is true and perhaps publishable. But the tests used to compute many of the \(p\)-values people still rely on today were developed over a century ago, when “computer” was still a job title. Now that we have digital computers and it’s standard practice to collect and analyze “big data,” the mathematical assumptions underlying many classical significance tests are being pushed beyond their limits.</description>
    </item>
    
    <item>
      <title></title>
      <link>/page/introstats/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/page/introstats/</guid>
      <description>Introductory statistics       code{white-space: pre;} pre:not([class]) { background-color: white; }  if (window.hljs) { hljs.configure({languages: []}); hljs.initHighlightingOnLoad(); if (document.readyState &amp;&amp; document.readyState === &#34;complete&#34;) { window.setTimeout(function() { hljs.initHighlighting(); }, 0); } }  h1 { font-size: 34px; } h1.title { font-size: 38px; } h2 { font-size: 30px; } h3 { font-size: 24px; } h4 { font-size: 18px; } h5 { font-size: 16px; } h6 { font-size: 12px; } .</description>
    </item>
    
    <item>
      <title></title>
      <link>/post/2019-11-18-a-concise-defense-of-significance/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/post/2019-11-18-a-concise-defense-of-significance/</guid>
      <description>A concise defense of statistical significance       code{white-space: pre;} pre:not([class]) { background-color: white; }  if (window.hljs) { hljs.configure({languages: []}); hljs.initHighlightingOnLoad(); if (document.readyState &amp;&amp; document.readyState === &#34;complete&#34;) { window.setTimeout(function() { hljs.initHighlighting(); }, 0); } }  h1 { font-size: 34px; } h1.title { font-size: 38px; } h2 { font-size: 30px; } h3 { font-size: 24px; } h4 { font-size: 18px; } h5 { font-size: 16px; } h6 { font-size: 12px; } .</description>
    </item>
    
    <item>
      <title>About me</title>
      <link>/page/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/page/about/</guid>
      <description>I&amp;rsquo;m a statistician and data scientist with a broad range of interests including theory, applications, and teaching with the R statistical programming language. My research focuses on common practices in machine learning and data science pipelines and addressing sources and types of error that have previously been overlooked. This includes, for example:
 Developing methods for inference after model selection such as p-values adjusted for selection bias Analyzing the social fairness of machine learning algorithms from a causal perspective  My work has been published in the Annals of Statistics and Advances in Neural Information Processing Systems (NIPS).</description>
    </item>
    
    <item>
      <title>Introductory statistics</title>
      <link>/page/introregression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/page/introregression/</guid>
      <description>Course description The objective of this course is to introduce students to the basic statistical techniques that are widely used in business and other fields. In particular, considerable attention will be devoted to the technique of regression analysis, which is a useful and powerful technique for modeling the relationships between variables of interest.
Syllabus Full syllabus here: pdf
Background material on topics prerequisite to this course, including lecture notes and a variety of textbook references, is available on the course page for Stat-UB.</description>
    </item>
    
    <item>
      <title>Introductory statistics</title>
      <link>/page/introstats/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/page/introstats/</guid>
      <description>Course description This course examines modern statistical methods as a basis for decision making in the face of uncertainty. Topics include probability theory, discrete and continuous distributions, hypothesis testing, estimation, and statistical quality control. With the aid of computers, these statistical methods are used to analyze data. Also presented are an introduction to statistical models and their application to decision making. Topics include the simple linear regression model, inference in regression analysis, sensitivity analysis, and multiple regression analysis.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/page/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/page/research/</guid>
      <description>My two areas of active work are summarized below with links to selected papers. More information can be found on my Google Scholar profile page.
Causal inference in fairness This work approaches fair machine learning from a causal inference perspective, arguing that determining what is fair is a similar challenge to determining causality.
Press Some of this work was covered in the New Scientist and 36Kr.
Publications  M. J.</description>
    </item>
    
    <item>
      <title>Teaching</title>
      <link>/page/teaching/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/page/teaching/</guid>
      <description>Course pages  Stat-UB.103: Introductory statistics (created by Vinu Abeywick) Stat-UB.103 (old): Statistics for business: control, regression, and forecasting Stat-UB.003: Regression and forecasting (page not active) Stats 390: Statistical Consulting Workshop (at Stanford, old page)  Selected links For the R programming language Installation: download and install the R language itself, then download and install the free desktop version of RStudio, finally, you may find this short, free book on the basics of R and RStudio helpful for getting started.</description>
    </item>
    
  </channel>
</rss>