---
title: "Lecture 3 - Summaries"
author: "Joshua Loftus"
date: "January 24, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Review: Observational studies

- Can't control and randomize
- Confounder: associated with both exposure and outcome
- Can (try to) control for confounders when they are measured
- Unobserved confounders are always a major limitation of observational studies
- RCTs are a higher standard of evidence

#### Summarizing data

We've got a bunch of data. What can we do with it? Look at a giant spreadsheet?

*How do we extract meaning from a collection of (many) observations?*

##### Today we will talk about

- Measures of central tendency
- Measures of dispersion

##### Notation for data

- Data as a list of numbers
- Number of observations $n$ is length of the list
- Write $x_1$ for the first number, $x_2$ for the second, ...
- In general $x_i$ denotes the $i$th number in the list.
- What's the last number? $x_n$

##### Measures of central tendency 

- The **mean** or (arithmetic) average of the data is sum of all the $x_i$'s divided by $n$
$$\bar x := \frac{1}{n}\sum_{i=1}^n x_i$$
- **Order statistics**:
- Write $x_{(1)}$ for the smallest number, $x_{(2)}$ for the second smallest, ...
- What's the largest? $x_{(n)}$
- $x_{(1)}, x_{(2)}, \ldots, x_{(n)}$ is a sorted list
- The **median** is the middle one if $n$ is odd, or average of middle two if $n$ is even
$$m := \frac{1}{2}(x_{(n/2)}+x_{(n/2+1)}) \quad \text{or} \quad x_{((n+1)/2)}$$
- Half of the data points are below $m$ and half above
- Counting how many times each unique number occurs gives a **table**
- A **mode** is a number which occurs the most number of times

*The mean is the most commonly used, but the others are more useful/meaningful in certain scenarios*

#### Measures of dispersion

- **Range**: $x_{(n)} - x_{(1)}$
- The (sample) **standard deviation** (or SD):
$$
s := \sqrt{\frac{1}{n-1}\sum_{i=1}^n(x_i - \bar x)^2}
$$
- (Why $n-1$? Otherwise $s$ would be too small. More on this another day)
- This is like an *average distance from each point to the overall average*
- **Quartiles**: 25% of the data points are below $Q_1$ and 75% above.
- $Q_2 = m$, and 25% of the data points are above $Q_3$.
- The **interquartile range** $IQR := Q_3 - Q_1$ contains the middle 50% of the data
- Another average distance from the center is **median absolute deviation**
$$
MAD := \text{median}(|x_i - m|)
$$
- This means: make a new list $|x_1 - m|, |x_2 - m|, ...$ and then find its median

*SD is the most commonly used*

#### A few interesting facts

- How far apart can $\bar x$ and $m$ be? Not too far: $| \bar x - m| \leq s$
- What % of the $x_i$'s are within distance $s$ from $\bar x$? Usually at least 68%
- **68-95-99 rule**: about what % of the $x_i$'s are within $s$, $2s$, $3s$ from $\bar x$, respectively
- e.g. about 99% of the $x_i$'s will satisfy
$$
\bar x - 3s \leq x_i \leq \bar x + 3s
$$
- Does this justify using measures of central tendency and spread as summaries of the data?

#### Some class survey responses

```{r}
data <- read.csv("class_survey.csv", header=T, stringsAsFactors = F)
names(data) <- c("time", "major", "job_title", "stat_relevant", "math_proficiency",
                 "stat_excited", "comp_proficiency", "skills", "takeaway", "topics",
                 "learning_value", "suggestion", "hobby", "hours_study", "hours_play",
                 "hours_work", "age", "gender", "distance")
names(data)
```

##### Summary of age

```{r}
mean(data$age, na.rm = TRUE)
median(data$age, na.rm = TRUE)
table(data$age)
```

##### Summary of distance

```{r}
library(lubridate)
has_numbers_in_it <- data$distance[grep("([[:digit:]])", data$distance)]
times <- gsub("^([0-9]*)$", "\\1:00", has_numbers_in_it)
times <- gsub("hour", ":00", fixed = T, times)
times <- gsub(" ", "", times)
times <- gsub("[[:alpha:]]", "", times)
times <- hm(times)
times <- 60*hour(times) + minute(times)
head(cbind(has_numbers_in_it, times))
summary(times)
```

```{r}
times <- times[!is.na(times)]
times <- times[times < 10000]
```

```{r}
mean(times, na.rm = TRUE)
median(times, na.rm = TRUE)
sd(times, na.rm = TRUE)
summary(times)
```

Let's try out the 68-95-99 rule

```{r}
x <- times
xbar <- mean(x)
s <- sd(x)
rbind(
mean(abs(x - xbar) <= s),
mean(abs(x - xbar) <= 2*s),
mean(abs(x - xbar) <= 3*s))
```

Well that's awkward... or is it?

```{r}
x <- data$hours_study
xbar <- mean(x)
s <- sd(x)
rbind(
mean(abs(x - xbar) <= s),
mean(abs(x - xbar) <= 2*s),
mean(abs(x - xbar) <= 3*s))
```