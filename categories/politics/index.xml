<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Politics on Joshua Loftus</title>
    <link>/categories/politics/</link>
    <description>Recent content in Politics on Joshua Loftus</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>lastname at nyu.edu (Joshua Loftus)</managingEditor>
    <webMaster>lastname at nyu.edu (Joshua Loftus)</webMaster>
    <lastBuildDate>Tue, 31 Jul 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/politics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Russian twitter trolls attacked Bernie too</title>
      <link>/post/russian-twitter-trolls-attacked-bernie-too/</link>
      <pubDate>Tue, 31 Jul 2018 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/post/russian-twitter-trolls-attacked-bernie-too/</guid>
      <description>(Foreign) Political influence campaigns on Twitter You may have seen stories about Twitter accounts operated by Russians attempting to influence the 2016 election in the United States. Much of the reporting that I’ve seen described a Simple Narrative: Russians tried to help trump and hurt Clinton, even supporting Bernie Sanders in order to attack Clinton. I’ve also seen plenty of Democrats on Twitter attacking Sanders over this. I have not seen any stories reporting the fact that many of these bots also attacked Sanders.</description>
    </item>
    
    <item>
      <title>Algorithmic fairness is as hard as causation</title>
      <link>/post/algorithmic-fairness-is-as-hard-as-causation/</link>
      <pubDate>Fri, 23 Feb 2018 00:00:00 +0000</pubDate>
      <author>lastname at nyu.edu (Joshua Loftus)</author>
      <guid>/post/algorithmic-fairness-is-as-hard-as-causation/</guid>
      <description>What is algorithmic fairness? (Feel free to skip this section if you’re already familiar with the topic.)
Algorithmic fairness is an interdisciplinary research field concerned with the various ways that algorithms may perpetuate or reinforce unfair legacies of our history, and how we might modify the alorithms or systems they are used in to prevent this. For example, if the training data used in a machine learning methods contains patterns caused by things like racism, sexism, ableism, or other types of injustice, then the model may learn those patterns and use them to make predictions and decisions that are unfair.</description>
    </item>
    
  </channel>
</rss>